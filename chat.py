import streamlit as st
import requests
from bs4 import BeautifulSoup
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
import os
from dotenv import load_dotenv
load_dotenv()

GOOGLE_API_KEY = os.getenv("GOOGLE_GEMINI_API_KEY")
WEBSITE_URL = "https://www.ceo.pro.vn/"

# --- L·∫•y v√† x·ª≠ l√Ω d·ªØ li·ªáu (thay WebBaseLoader) ---
@st.cache_resource
def load_and_process_data(url, api_key):
    resp = requests.get(url)
    soup = BeautifulSoup(resp.text, "html.parser")
    for script in soup(["script", "style"]):
        script.decompose()
    text = soup.get_text(separator="\n")
    
    from langchain.schema import Document
    doc = Document(page_content=text, metadata={"source": url})
    
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    chunks = text_splitter.split_documents([doc])
    
    vector_store = Chroma.from_documents(
        chunks,
        embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    )
    
    return vector_store.as_retriever(search_kwargs={"k": 3})

# --- Prompt template ---
prompt_template = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch v√† th√¢n thi·ªán, c√≥ nhi·ªám v·ª• tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ch·ªâ d·ª±a tr√™n th√¥ng tin t·ª´ trang web ƒë∆∞·ª£c cung c·∫•p.
H√£y tu√¢n th·ªß c√°c quy t·∫Øc sau:
1. Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin trong ph·∫ßn "Ng·ªØ c·∫£nh" d∆∞·ªõi ƒë√¢y ƒë·ªÉ tr·∫£ l·ªùi.
2. N·∫øu th√¥ng tin kh√¥ng c√≥ trong ng·ªØ c·∫£nh, h√£y tr·∫£ l·ªùi m·ªôt c√°ch l·ªãch s·ª± r·∫±ng: "T√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin n√†y tr√™n trang web." ƒê·ª´ng c·ªë b·ªãa ra c√¢u tr·∫£ l·ªùi.
3. Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, m·ªôt c√°ch r√µ r√†ng v√† chuy√™n nghi·ªáp.

Ng·ªØ c·∫£nh:
{context}

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {question}

C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n:"""

PROMPT = PromptTemplate(template=prompt_template, input_variables=["context", "question"])

# --- Giao di·ªán Streamlit ---
st.set_page_config(page_title="Chatbot Website CEO Pro Club", page_icon="ü§ñ")
st.title("ü§ñ Chatbot H·ªó Tr·ª£ Th√¥ng Tin CEO Pro Club")
st.caption(f"T√¥i l√† tr·ª£ l√Ω ·∫£o, s·∫µn s√†ng tr·∫£ l·ªùi c√°c c√¢u h·ªèi t·ª´ trang: {WEBSITE_URL}")

try:
    retriever = load_and_process_data(WEBSITE_URL, GOOGLE_API_KEY)
    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash", google_api_key=GOOGLE_API_KEY, temperature=0.7)
    
    chain_type_kwargs = {"prompt": PROMPT}
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs=chain_type_kwargs,
        return_source_documents=True
    )

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω ·∫£o c·ªßa trang web n√†y. B·∫°n c·∫ßn t√¨m th√¥ng tin g√¨ ·∫°?"}]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("B·∫°n mu·ªën h·ªèi g√¨ v·ªÅ n·ªôi dung trang web?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("ƒêang t√¨m ki·∫øm v√† t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi..."):
                response = qa_chain(prompt)
                answer = response['result']
                st.markdown(answer)
        
        st.session_state.messages.append({"role": "assistant", "content": answer})

except Exception as e:
    st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
    st.info("Vui l√≤ng ki·ªÉm tra l·∫°i Google API Key v√† URL c·ªßa website.")
