__import__('pysqlite3')
import sys
sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')

import asyncio
import streamlit as st
# V·∫´n import c√°c th√†nh ph·∫ßn t·ª´ langchain-core ho·∫∑c langchain
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# Thay ƒë·ªïi c√°c import ƒë·ªÉ tr·ªè ƒë·∫øn c√°c g√≥i c·ª• th·ªÉ h∆°n
from langchain_community.document_loaders import WebBaseLoader # <-- THAY ƒê·ªîI
from langchain_community.vectorstores import Chroma           # <-- THAY ƒê·ªîI
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI

import os
from dotenv import load_dotenv
load_dotenv()

def sanitize_for_markdown(text: str) -> str:
    """
    H√†m n√†y thay th·∫ø c√°c k√Ω t·ª± c√≥ th·ªÉ g√¢y l·ªói cho b·ªô render Markdown JavaScript
    tr√™n m·ªôt s·ªë tr√¨nh duy·ªát di ƒë·ªông. C·ª• th·ªÉ l√† d·∫•u `?` trong c√°c nh√≥m regex.
    """
    # Thay th·∫ø c√°c k√Ω t·ª± c√≥ th·ªÉ g√¢y ra l·ªói regex kh√¥ng h·ª£p l·ªá
    # V√≠ d·ª•: m·ªôt chu·ªói nh∆∞ `(?<` c√≥ th·ªÉ g√¢y l·ªói tr√™n c√°c tr√¨nh duy·ªát c≈©.
    # Ta c√≥ th·ªÉ thay th·∫ø c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát h∆°n, nh∆∞ng b·∫Øt ƒë·∫ßu v·ªõi d·∫•u `\` l√† ph·ªï bi·∫øn nh·∫•t.
    return text.replace('\\', '\\\\')

GOOGLE_API_KEY = st.secrets["GOOGLE_GEMINI_API_KEY"]
WEBSITE_URL = "https://www.ceo.pro.vn/"

# --- H√ÄM T·∫¢I D·ªÆ LI·ªÜU V√Ä X·ª¨ L√ù ---
@st.cache_resource
def load_and_process_data(url, api_key):
    # T·∫†O V√Ä SET EVENT LOOP M·ªöI CHO LU·ªíNG HI·ªÜN T·∫†I
    asyncio.set_event_loop(asyncio.new_event_loop()) # <-- TH√äM D√íNG N√ÄY

    loader = WebBaseLoader(url)
    data = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    chunks = text_splitter.split_documents(data)
    vector_store = Chroma.from_documents(
        chunks,
        embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    )
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    return retriever

# --- T·∫†O PROMPT TEMPLATE ƒê·ªÇ SET ROLE ---
prompt_template = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI h·ªØu √≠ch v√† th√¢n thi·ªán, c√≥ nhi·ªám v·ª• tr·∫£ l·ªùi c√°c c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng ch·ªâ d·ª±a tr√™n th√¥ng tin t·ª´ trang web ƒë∆∞·ª£c cung c·∫•p.
Tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát, m·ªôt c√°ch r√µ r√†ng v√† chuy√™n nghi·ªáp.

Ng·ªØ c·∫£nh:
{context}

C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {question}

C√¢u tr·∫£ l·ªùi c·ªßa b·∫°n:"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)

# --- GIAO DI·ªÜN STREAMLIT ---
st.set_page_config(page_title="Chatbot Website v·ªõi Gemini", page_icon="ü§ñ")
st.title("ü§ñ Chatbot H·ªó Tr·ª£ Th√¥ng Tin Website")
st.caption(f"T√¥i l√† tr·ª£ l√Ω ·∫£o, s·∫µn s√†ng tr·∫£ l·ªùi c√°c c√¢u h·ªèi t·ª´ trang: {WEBSITE_URL}")

try:
    retriever = load_and_process_data(WEBSITE_URL, GOOGLE_API_KEY)
    llm = ChatGoogleGenerativeAI(model="gemini-2.5-flash", google_api_key=GOOGLE_API_KEY, temperature=0.7)
    
    chain_type_kwargs = {"prompt": PROMPT}
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs=chain_type_kwargs,
        return_source_documents=True
    )

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "Ch√†o b·∫°n! T√¥i l√† tr·ª£ l√Ω ·∫£o c·ªßa trang web n√†y. B·∫°n c·∫ßn t√¨m th√¥ng tin g√¨ ·∫°?"}]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            # L√†m s·∫°ch t·∫•t c·∫£ n·ªôi dung tr∆∞·ªõc khi render
            st.markdown(sanitize_for_markdown(message["content"]))


    if prompt := st.chat_input("B·∫°n mu·ªën h·ªèi g√¨ v·ªÅ n·ªôi dung trang web?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)


        with st.chat_message("assistant"):
            with st.spinner("ƒêang t√¨m ki·∫øm v√† t·ªïng h·ª£p c√¢u tr·∫£ l·ªùi..."):
                response_dict = qa_chain.invoke(prompt)
                raw_answer = response_dict['result']
                
                # L√†m s·∫°ch c√¢u tr·∫£ l·ªùi tr∆∞·ªõc khi hi·ªÉn th·ªã
                sanitized_answer = sanitize_for_markdown(raw_answer)
                
                st.markdown(sanitized_answer) # <-- Hi·ªÉn th·ªã n·ªôi dung ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch
        
        # L∆∞u c√¢u tr·∫£ l·ªùi g·ªëc (ch∆∞a l√†m s·∫°ch) v√†o l·ªãch s·ª≠
        st.session_state.messages.append({"role": "assistant", "content": raw_answer})

except Exception as e:
    st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")
    st.info("Vui l√≤ng ki·ªÉm tra l·∫°i Google API Key v√† URL c·ªßa website.")
