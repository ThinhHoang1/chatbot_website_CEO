import streamlit as st
from langchain.document_loaders import WebBaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate # <-- Import thÃªm
import os
# Load .env
from dotenv import load_dotenv
load_dotenv()

# Láº¥y API key tá»« biáº¿n mÃ´i trÆ°á»ng
GOOGLE_API_KEY = os.getenv("GOOGLE_GEMINI_API_KEY")
# --- Cáº¤U HÃŒNH ---
WEBSITE_URL = "https://www.ceo.pro.vn/" 

# --- HÃ€M Táº¢I Dá»® LIá»†U VÃ€ Xá»¬ LÃ ---
@st.cache_resource
def load_and_process_data(url, api_key):
    loader = WebBaseLoader(url)
    data = loader.load()
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1500, chunk_overlap=200)
    chunks = text_splitter.split_documents(data)
    vector_store = Chroma.from_documents(
        chunks,
        embedding=GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=api_key)
    )
    retriever = vector_store.as_retriever(search_kwargs={"k": 3})
    return retriever

# --- Táº O PROMPT TEMPLATE Äá»‚ SET ROLE ---
prompt_template = """Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»¯u Ã­ch vÃ  thÃ¢n thiá»‡n, cÃ³ nhiá»‡m vá»¥ tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng chá»‰ dá»±a trÃªn thÃ´ng tin tá»« trang web Ä‘Æ°á»£c cung cáº¥p.
HÃ£y tuÃ¢n thá»§ cÃ¡c quy táº¯c sau:
1. Chá»‰ sá»­ dá»¥ng thÃ´ng tin trong pháº§n "Ngá»¯ cáº£nh" dÆ°á»›i Ä‘Ã¢y Ä‘á»ƒ tráº£ lá»i.
2. Náº¿u thÃ´ng tin khÃ´ng cÃ³ trong ngá»¯ cáº£nh, hÃ£y tráº£ lá»i má»™t cÃ¡ch lá»‹ch sá»± ráº±ng: "TÃ´i khÃ´ng tÃ¬m tháº¥y thÃ´ng tin nÃ y trÃªn trang web." Äá»«ng cá»‘ bá»‹a ra cÃ¢u tráº£ lá»i.
3. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, má»™t cÃ¡ch rÃµ rÃ ng vÃ  chuyÃªn nghiá»‡p.

Ngá»¯ cáº£nh:
{context}

CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {question}

CÃ¢u tráº£ lá»i cá»§a báº¡n:"""

PROMPT = PromptTemplate(
    template=prompt_template, input_variables=["context", "question"]
)

# --- GIAO DIá»†N STREAMLIT ---
st.set_page_config(page_title="Chatbot Website CEO Pro Club", page_icon="ðŸ¤–")
st.title("ðŸ¤– Chatbot Há»— Trá»£ ThÃ´ng Tin CEO Pro Club")
st.caption(f"TÃ´i lÃ  trá»£ lÃ½ áº£o, sáºµn sÃ ng tráº£ lá»i cÃ¡c cÃ¢u há»i tá»« trang: {WEBSITE_URL}")

try:
    retriever = load_and_process_data(WEBSITE_URL, GOOGLE_API_KEY)
    llm = ChatGoogleGenerativeAI(model="models/gemini-2.5-flash", google_api_key=GOOGLE_API_KEY, temperature=0.7)
    
    chain_type_kwargs = {"prompt": PROMPT}
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs=chain_type_kwargs,
        return_source_documents=True # Tráº£ vá» cáº£ nguá»“n
    )

    if "messages" not in st.session_state:
        st.session_state.messages = [{"role": "assistant", "content": "ChÃ o báº¡n! TÃ´i lÃ  trá»£ lÃ½ áº£o cá»§a trang web nÃ y. Báº¡n cáº§n tÃ¬m thÃ´ng tin gÃ¬ áº¡?"}]

    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    if prompt := st.chat_input("Báº¡n muá»‘n há»i gÃ¬ vá» ná»™i dung trang web?"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Äang tÃ¬m kiáº¿m vÃ  tá»•ng há»£p cÃ¢u tráº£ lá»i..."):
                response = qa_chain(prompt) # Gá»i chain
                answer = response['result'] # Láº¥y cÃ¢u tráº£ lá»i
                st.markdown(answer)
        
        st.session_state.messages.append({"role": "assistant", "content": answer})

except Exception as e:
    st.error(f"ÄÃ£ xáº£y ra lá»—i: {e}")
    st.info("Vui lÃ²ng kiá»ƒm tra láº¡i Google API Key vÃ  URL cá»§a website.")